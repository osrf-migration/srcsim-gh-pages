{"links": {"self": {"href": "data/repositories/osrf/srcsim/issues/29/comments/33089714.json"}, "html": {"href": "#!/osrf/srcsim/issues/29#comment-33089714"}}, "issue": {"links": {"self": {"href": "data/repositories/osrf/srcsim/issues/29.json"}}, "type": "issue", "id": 29, "repository": {"links": {"self": {"href": "data/repositories/osrf/srcsim.json"}, "html": {"href": "#!/osrf/srcsim"}, "avatar": {"href": "data/bytebucket.org/ravatar/{c41021d9-0217-4628-999d-7f8d82f98dcb}ts=c_plus_plus"}}, "type": "repository", "name": "srcsim", "full_name": "osrf/srcsim", "uuid": "{c41021d9-0217-4628-999d-7f8d82f98dcb}"}, "title": "gazebo head frame or ROS head frame?"}, "content": {"raw": "Is that the same as the ROS upperNeckPitchLink frame?  Because I tried using that, generated an answer file, ran it through the score test and it was not correct.  Is there some other transform needed to go from the ROS frame to the Gazebo frame?  \n\nI originally tested my results by inverting the image (as Nathan says to do in the earlier comment in this issue), then calculating the location of the light, transforming the results in ROS from \"left_camera_optical_frame\" to \"head,\" including the required axis change for going from a camera image to a world location.  I then generate a marker using that location, publish it, and see in rviz that the marker exactly overlies the 3d point cloud location of the light.  That works fine, looks perfect. \n\nHowever, with the inverted camera image and the inverted head frame and the not inverted upperNeckPitchLink frame, and maybe differences in ROS vs Gazebo frames, it is pretty hard to sort out how to report the results.", "markup": "markdown", "html": "<p>Is that the same as the ROS upperNeckPitchLink frame?  Because I tried using that, generated an answer file, ran it through the score test and it was not correct.  Is there some other transform needed to go from the ROS frame to the Gazebo frame?  </p>\n<p>I originally tested my results by inverting the image (as Nathan says to do in the earlier comment in this issue), then calculating the location of the light, transforming the results in ROS from \"left_camera_optical_frame\" to \"head,\" including the required axis change for going from a camera image to a world location.  I then generate a marker using that location, publish it, and see in rviz that the marker exactly overlies the 3d point cloud location of the light.  That works fine, looks perfect. </p>\n<p>However, with the inverted camera image and the inverted head frame and the not inverted upperNeckPitchLink frame, and maybe differences in ROS vs Gazebo frames, it is pretty hard to sort out how to report the results.</p>", "type": "rendered"}, "created_on": "2016-12-22T01:18:55.578741+00:00", "user": {"display_name": "dan", "uuid": "{a93bd0ec-35fc-49a5-aa8a-b0b57403c2d0}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Ba93bd0ec-35fc-49a5-aa8a-b0b57403c2d0%7D"}, "html": {"href": "https://bitbucket.org/%7Ba93bd0ec-35fc-49a5-aa8a-b0b57403c2d0%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/dd56d3105d7602d83d5c35a320f6b36cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsD-6.png"}}, "nickname": "dan77062", "type": "user", "account_id": "557058:e0e36946-cb60-4776-8f47-2e9a0285ad35"}, "updated_on": "2016-12-22T01:41:00.737090+00:00", "type": "issue_comment", "id": 33089714}