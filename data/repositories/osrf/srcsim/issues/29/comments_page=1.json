{"pagelen": 100, "values": [{"links": {"self": {"href": "data/repositories/osrf/srcsim/issues/29/comments/32364611.json"}, "html": {"href": "#!/osrf/srcsim/issues/29#comment-32364611"}}, "issue": {"links": {"self": {"href": "data/repositories/osrf/srcsim/issues/29.json"}}, "type": "issue", "id": 29, "repository": {"links": {"self": {"href": "data/repositories/osrf/srcsim.json"}, "html": {"href": "#!/osrf/srcsim"}, "avatar": {"href": "data/bytebucket.org/ravatar/{c41021d9-0217-4628-999d-7f8d82f98dcb}ts=c_plus_plus"}}, "type": "repository", "name": "srcsim", "full_name": "osrf/srcsim", "uuid": "{c41021d9-0217-4628-999d-7f8d82f98dcb}"}, "title": "gazebo head frame or ROS head frame?"}, "content": {"raw": "We will accept values in either frame. ", "markup": "markdown", "html": "<p>We will accept values in either frame. </p>", "type": "rendered"}, "created_on": "2016-11-22T20:50:37.268083+00:00", "user": {"display_name": "Nate Koenig", "uuid": "{c862cdd9-fcc8-4419-9fc7-e20db14b8fcb}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bc862cdd9-fcc8-4419-9fc7-e20db14b8fcb%7D"}, "html": {"href": "https://bitbucket.org/%7Bc862cdd9-fcc8-4419-9fc7-e20db14b8fcb%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:095b1e12-74ed-4e20-b44f-2f0745b616e0/ca24bb11-4787-4b14-a20d-d91835e9bde2/128"}}, "nickname": "Nathan Koenig", "type": "user", "account_id": "557058:095b1e12-74ed-4e20-b44f-2f0745b616e0"}, "updated_on": null, "type": "issue_comment", "id": 32364611}, {"links": {"self": {"href": "data/repositories/osrf/srcsim/issues/29/comments/32365716.json"}, "html": {"href": "#!/osrf/srcsim/issues/29#comment-32365716"}}, "issue": {"links": {"self": {"href": "data/repositories/osrf/srcsim/issues/29.json"}}, "type": "issue", "id": 29, "repository": {"links": {"self": {"href": "data/repositories/osrf/srcsim.json"}, "html": {"href": "#!/osrf/srcsim"}, "avatar": {"href": "data/bytebucket.org/ravatar/{c41021d9-0217-4628-999d-7f8d82f98dcb}ts=c_plus_plus"}}, "type": "repository", "name": "srcsim", "full_name": "osrf/srcsim", "uuid": "{c41021d9-0217-4628-999d-7f8d82f98dcb}"}, "title": "gazebo head frame or ROS head frame?"}, "content": {"raw": "OK, thanks for the quick feedback.", "markup": "markdown", "html": "<p>OK, thanks for the quick feedback.</p>", "type": "rendered"}, "created_on": "2016-11-22T21:56:43.810187+00:00", "user": {"display_name": "dan", "uuid": "{a93bd0ec-35fc-49a5-aa8a-b0b57403c2d0}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Ba93bd0ec-35fc-49a5-aa8a-b0b57403c2d0%7D"}, "html": {"href": "https://bitbucket.org/%7Ba93bd0ec-35fc-49a5-aa8a-b0b57403c2d0%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/dd56d3105d7602d83d5c35a320f6b36cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsD-6.png"}}, "nickname": "dan77062", "type": "user", "account_id": "557058:e0e36946-cb60-4776-8f47-2e9a0285ad35"}, "updated_on": "2016-11-22T21:57:00.729640+00:00", "type": "issue_comment", "id": 32365716}, {"links": {"self": {"href": "data/repositories/osrf/srcsim/issues/29/comments/32448084.json"}, "html": {"href": "#!/osrf/srcsim/issues/29#comment-32448084"}}, "issue": {"links": {"self": {"href": "data/repositories/osrf/srcsim/issues/29.json"}}, "type": "issue", "id": 29, "repository": {"links": {"self": {"href": "data/repositories/osrf/srcsim.json"}, "html": {"href": "#!/osrf/srcsim"}, "avatar": {"href": "data/bytebucket.org/ravatar/{c41021d9-0217-4628-999d-7f8d82f98dcb}ts=c_plus_plus"}}, "type": "repository", "name": "srcsim", "full_name": "osrf/srcsim", "uuid": "{c41021d9-0217-4628-999d-7f8d82f98dcb}"}, "title": "gazebo head frame or ROS head frame?"}, "content": {"raw": "Thinking about this more and also looking at Issue #22, I'm not sure I made my question clear.  The image below shows that the transforms do not take into account the fact that the image is inverted. The +z axis (blue) of the head frame is up relative to gravity but the lower part of the console in the point cloud is shown as \"above\" the head. The question is: should we invert the image and return the correct physical coordinates in the world or should we use the published transforms with the result that the coordinates look correct in RViz but are in fact not physically where the light is with respect to the robot's head.\n\n![qual1_inverted_image.png](data/bitbucket.org/repo/xEbAAe/images/4039078901-qual1_inverted_image.png)", "markup": "markdown", "html": "<p>Thinking about this more and also looking at Issue <a href=\"#!/osrf/srcsim/issues/22/valkyrie-head-orientation\" rel=\"nofollow\" title=\"Valkyrie head orientation\" class=\"ap-connect-link\"><s>#22</s></a>, I'm not sure I made my question clear.  The image below shows that the transforms do not take into account the fact that the image is inverted. The +z axis (blue) of the head frame is up relative to gravity but the lower part of the console in the point cloud is shown as \"above\" the head. The question is: should we invert the image and return the correct physical coordinates in the world or should we use the published transforms with the result that the coordinates look correct in RViz but are in fact not physically where the light is with respect to the robot's head.</p>\n<p><img alt=\"qual1_inverted_image.png\" src=\"data/bitbucket.org/repo/xEbAAe/images/4039078901-qual1_inverted_image.png\" /></p>", "type": "rendered"}, "created_on": "2016-11-25T19:01:47.017023+00:00", "user": {"display_name": "dan", "uuid": "{a93bd0ec-35fc-49a5-aa8a-b0b57403c2d0}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Ba93bd0ec-35fc-49a5-aa8a-b0b57403c2d0%7D"}, "html": {"href": "https://bitbucket.org/%7Ba93bd0ec-35fc-49a5-aa8a-b0b57403c2d0%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/dd56d3105d7602d83d5c35a320f6b36cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsD-6.png"}}, "nickname": "dan77062", "type": "user", "account_id": "557058:e0e36946-cb60-4776-8f47-2e9a0285ad35"}, "updated_on": null, "type": "issue_comment", "id": 32448084}, {"links": {"self": {"href": "data/repositories/osrf/srcsim/issues/29/comments/32502292.json"}, "html": {"href": "#!/osrf/srcsim/issues/29#comment-32502292"}}, "issue": {"links": {"self": {"href": "data/repositories/osrf/srcsim/issues/29.json"}}, "type": "issue", "id": 29, "repository": {"links": {"self": {"href": "data/repositories/osrf/srcsim.json"}, "html": {"href": "#!/osrf/srcsim"}, "avatar": {"href": "data/bytebucket.org/ravatar/{c41021d9-0217-4628-999d-7f8d82f98dcb}ts=c_plus_plus"}}, "type": "repository", "name": "srcsim", "full_name": "osrf/srcsim", "uuid": "{c41021d9-0217-4628-999d-7f8d82f98dcb}"}, "title": "gazebo head frame or ROS head frame?"}, "content": {"raw": "That is a good point.\n\nYou should invert the image so that the reported light location is physically accurate relative to the head frame. I'll update the tutorial as well.", "markup": "markdown", "html": "<p>That is a good point.</p>\n<p>You should invert the image so that the reported light location is physically accurate relative to the head frame. I'll update the tutorial as well.</p>", "type": "rendered"}, "created_on": "2016-11-28T19:49:48.318668+00:00", "user": {"display_name": "Nate Koenig", "uuid": "{c862cdd9-fcc8-4419-9fc7-e20db14b8fcb}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bc862cdd9-fcc8-4419-9fc7-e20db14b8fcb%7D"}, "html": {"href": "https://bitbucket.org/%7Bc862cdd9-fcc8-4419-9fc7-e20db14b8fcb%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:095b1e12-74ed-4e20-b44f-2f0745b616e0/ca24bb11-4787-4b14-a20d-d91835e9bde2/128"}}, "nickname": "Nathan Koenig", "type": "user", "account_id": "557058:095b1e12-74ed-4e20-b44f-2f0745b616e0"}, "updated_on": null, "type": "issue_comment", "id": 32502292}, {"links": {"self": {"href": "data/repositories/osrf/srcsim/issues/29/comments/32502514.json"}, "html": {"href": "#!/osrf/srcsim/issues/29#comment-32502514"}}, "issue": {"links": {"self": {"href": "data/repositories/osrf/srcsim/issues/29.json"}}, "type": "issue", "id": 29, "repository": {"links": {"self": {"href": "data/repositories/osrf/srcsim.json"}, "html": {"href": "#!/osrf/srcsim"}, "avatar": {"href": "data/bytebucket.org/ravatar/{c41021d9-0217-4628-999d-7f8d82f98dcb}ts=c_plus_plus"}}, "type": "repository", "name": "srcsim", "full_name": "osrf/srcsim", "uuid": "{c41021d9-0217-4628-999d-7f8d82f98dcb}"}, "title": "gazebo head frame or ROS head frame?"}, "content": {"raw": "I'm concerned that the different inversions used by competitors are going to produce results that are valid but not *correct* as judged by the competition. Can either another reference frame be used that handles the inversion or a standard ROS inversion process be provided?", "markup": "markdown", "html": "<p>I'm concerned that the different inversions used by competitors are going to produce results that are valid but not <em>correct</em> as judged by the competition. Can either another reference frame be used that handles the inversion or a standard ROS inversion process be provided?</p>", "type": "rendered"}, "created_on": "2016-11-28T19:58:45.031267+00:00", "user": {"display_name": "Rud Merriam", "uuid": "{79efa10c-b8b6-4b55-9d05-7d0057e235cb}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B79efa10c-b8b6-4b55-9d05-7d0057e235cb%7D"}, "html": {"href": "https://bitbucket.org/%7B79efa10c-b8b6-4b55-9d05-7d0057e235cb%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:c6ed1bc6-3112-49ac-9453-b3846fe562dc/5c7bde69-befb-417b-9aae-9db0c9a59777/128"}}, "nickname": "rmerriam", "type": "user", "account_id": "557058:c6ed1bc6-3112-49ac-9453-b3846fe562dc"}, "updated_on": null, "type": "issue_comment", "id": 32502514}, {"links": {"self": {"href": "data/repositories/osrf/srcsim/issues/29/comments/32538985.json"}, "html": {"href": "#!/osrf/srcsim/issues/29#comment-32538985"}}, "issue": {"links": {"self": {"href": "data/repositories/osrf/srcsim/issues/29.json"}}, "type": "issue", "id": 29, "repository": {"links": {"self": {"href": "data/repositories/osrf/srcsim.json"}, "html": {"href": "#!/osrf/srcsim"}, "avatar": {"href": "data/bytebucket.org/ravatar/{c41021d9-0217-4628-999d-7f8d82f98dcb}ts=c_plus_plus"}}, "type": "repository", "name": "srcsim", "full_name": "osrf/srcsim", "uuid": "{c41021d9-0217-4628-999d-7f8d82f98dcb}"}, "title": "gazebo head frame or ROS head frame?"}, "content": {"raw": "Thanks for the clear guidance.  Rud is right that there probably needs to be a standard way to invert the image.  However, I am fine with waiting for the scoring script and seeing how it goes with just inverting the image directly.", "markup": "markdown", "html": "<p>Thanks for the clear guidance.  Rud is right that there probably needs to be a standard way to invert the image.  However, I am fine with waiting for the scoring script and seeing how it goes with just inverting the image directly.</p>", "type": "rendered"}, "created_on": "2016-11-30T01:00:58.423456+00:00", "user": {"display_name": "dan", "uuid": "{a93bd0ec-35fc-49a5-aa8a-b0b57403c2d0}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Ba93bd0ec-35fc-49a5-aa8a-b0b57403c2d0%7D"}, "html": {"href": "https://bitbucket.org/%7Ba93bd0ec-35fc-49a5-aa8a-b0b57403c2d0%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/dd56d3105d7602d83d5c35a320f6b36cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsD-6.png"}}, "nickname": "dan77062", "type": "user", "account_id": "557058:e0e36946-cb60-4776-8f47-2e9a0285ad35"}, "updated_on": null, "type": "issue_comment", "id": 32538985}, {"links": {"self": {"href": "data/repositories/osrf/srcsim/issues/29/comments/32648944.json"}, "html": {"href": "#!/osrf/srcsim/issues/29#comment-32648944"}}, "issue": {"links": {"self": {"href": "data/repositories/osrf/srcsim/issues/29.json"}}, "type": "issue", "id": 29, "repository": {"links": {"self": {"href": "data/repositories/osrf/srcsim.json"}, "html": {"href": "#!/osrf/srcsim"}, "avatar": {"href": "data/bytebucket.org/ravatar/{c41021d9-0217-4628-999d-7f8d82f98dcb}ts=c_plus_plus"}}, "type": "repository", "name": "srcsim", "full_name": "osrf/srcsim", "uuid": "{c41021d9-0217-4628-999d-7f8d82f98dcb}"}, "title": "gazebo head frame or ROS head frame?"}, "content": {"raw": "What exactly is the \"head frame\"? where is the 0,0,0 coordinate. I don't see any reference to the head in the world model in Gazebo's left hand panel. When I click on \"upperNeckPitchLink\" I see a box that surrounds the head. Is that the \"head frame\"? If so where is 0,0,0, the center, a corner?\n\nAlso, I get an offset from the stereo depth data depending on which eye is reference. Are there some dimensions of the head/multsensor to be able to calculate accurately the total offsets.", "markup": "markdown", "html": "<p>What exactly is the \"head frame\"? where is the 0,0,0 coordinate. I don't see any reference to the head in the world model in Gazebo's left hand panel. When I click on \"upperNeckPitchLink\" I see a box that surrounds the head. Is that the \"head frame\"? If so where is 0,0,0, the center, a corner?</p>\n<p>Also, I get an offset from the stereo depth data depending on which eye is reference. Are there some dimensions of the head/multsensor to be able to calculate accurately the total offsets.</p>", "type": "rendered"}, "created_on": "2016-12-04T06:07:33.946763+00:00", "user": {"display_name": "mocorobo", "uuid": "{0e09769a-52a9-4036-891c-9b58d9c43401}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B0e09769a-52a9-4036-891c-9b58d9c43401%7D"}, "html": {"href": "https://bitbucket.org/%7B0e09769a-52a9-4036-891c-9b58d9c43401%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/41014f87d0be5e02393531e702539c82d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsM-1.png"}}, "nickname": "mocorobo", "type": "user", "account_id": "557058:91d63c8e-a67c-4dad-a84a-75eca07d4807"}, "updated_on": null, "type": "issue_comment", "id": 32648944}, {"links": {"self": {"href": "data/repositories/osrf/srcsim/issues/29/comments/33088273.json"}, "html": {"href": "#!/osrf/srcsim/issues/29#comment-33088273"}}, "issue": {"links": {"self": {"href": "data/repositories/osrf/srcsim/issues/29.json"}}, "type": "issue", "id": 29, "repository": {"links": {"self": {"href": "data/repositories/osrf/srcsim.json"}, "html": {"href": "#!/osrf/srcsim"}, "avatar": {"href": "data/bytebucket.org/ravatar/{c41021d9-0217-4628-999d-7f8d82f98dcb}ts=c_plus_plus"}}, "type": "repository", "name": "srcsim", "full_name": "osrf/srcsim", "uuid": "{c41021d9-0217-4628-999d-7f8d82f98dcb}"}, "title": "gazebo head frame or ROS head frame?"}, "content": {"raw": "@mocorobo , you're right that there's no head frame within Gazebo. For this task's purpose, you can use the `upperNeckPitchLink` frame. You can visualize it in Gazebo:\n\n![headframe.png](data/bitbucket.org/repo/xEbAAe/images/1546678982-headframe.png)\n\nYou can find all the offsets in the robot's description.\n\n**tl; dr**\n\nThe `head` frame disappears for Gazebo during the conversion from URDF to SDF. But you can still use it in RViz.", "markup": "markdown", "html": "<p>@mocorobo , you're right that there's no head frame within Gazebo. For this task's purpose, you can use the <code>upperNeckPitchLink</code> frame. You can visualize it in Gazebo:</p>\n<p><img alt=\"headframe.png\" src=\"data/bitbucket.org/repo/xEbAAe/images/1546678982-headframe.png\" /></p>\n<p>You can find all the offsets in the robot's description.</p>\n<p><strong>tl; dr</strong></p>\n<p>The <code>head</code> frame disappears for Gazebo during the conversion from URDF to SDF. But you can still use it in RViz.</p>", "type": "rendered"}, "created_on": "2016-12-21T22:32:22.037658+00:00", "user": {"display_name": "Louise Poubel", "uuid": "{5cfa2075-477b-4ded-bdb9-8d2479544ec4}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B5cfa2075-477b-4ded-bdb9-8d2479544ec4%7D"}, "html": {"href": "https://bitbucket.org/%7B5cfa2075-477b-4ded-bdb9-8d2479544ec4%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:6ff86fcb-b7ab-44a5-b8a6-f6d9cae8b6e8/7d903d90-c5ea-4182-b7ef-0d467e9e1c74/128"}}, "nickname": "chapulina", "type": "user", "account_id": "557058:6ff86fcb-b7ab-44a5-b8a6-f6d9cae8b6e8"}, "updated_on": null, "type": "issue_comment", "id": 33088273}, {"links": {"self": {"href": "data/repositories/osrf/srcsim/issues/29/comments/33089714.json"}, "html": {"href": "#!/osrf/srcsim/issues/29#comment-33089714"}}, "issue": {"links": {"self": {"href": "data/repositories/osrf/srcsim/issues/29.json"}}, "type": "issue", "id": 29, "repository": {"links": {"self": {"href": "data/repositories/osrf/srcsim.json"}, "html": {"href": "#!/osrf/srcsim"}, "avatar": {"href": "data/bytebucket.org/ravatar/{c41021d9-0217-4628-999d-7f8d82f98dcb}ts=c_plus_plus"}}, "type": "repository", "name": "srcsim", "full_name": "osrf/srcsim", "uuid": "{c41021d9-0217-4628-999d-7f8d82f98dcb}"}, "title": "gazebo head frame or ROS head frame?"}, "content": {"raw": "Is that the same as the ROS upperNeckPitchLink frame?  Because I tried using that, generated an answer file, ran it through the score test and it was not correct.  Is there some other transform needed to go from the ROS frame to the Gazebo frame?  \n\nI originally tested my results by inverting the image (as Nathan says to do in the earlier comment in this issue), then calculating the location of the light, transforming the results in ROS from \"left_camera_optical_frame\" to \"head,\" including the required axis change for going from a camera image to a world location.  I then generate a marker using that location, publish it, and see in rviz that the marker exactly overlies the 3d point cloud location of the light.  That works fine, looks perfect. \n\nHowever, with the inverted camera image and the inverted head frame and the not inverted upperNeckPitchLink frame, and maybe differences in ROS vs Gazebo frames, it is pretty hard to sort out how to report the results.", "markup": "markdown", "html": "<p>Is that the same as the ROS upperNeckPitchLink frame?  Because I tried using that, generated an answer file, ran it through the score test and it was not correct.  Is there some other transform needed to go from the ROS frame to the Gazebo frame?  </p>\n<p>I originally tested my results by inverting the image (as Nathan says to do in the earlier comment in this issue), then calculating the location of the light, transforming the results in ROS from \"left_camera_optical_frame\" to \"head,\" including the required axis change for going from a camera image to a world location.  I then generate a marker using that location, publish it, and see in rviz that the marker exactly overlies the 3d point cloud location of the light.  That works fine, looks perfect. </p>\n<p>However, with the inverted camera image and the inverted head frame and the not inverted upperNeckPitchLink frame, and maybe differences in ROS vs Gazebo frames, it is pretty hard to sort out how to report the results.</p>", "type": "rendered"}, "created_on": "2016-12-22T01:18:55.578741+00:00", "user": {"display_name": "dan", "uuid": "{a93bd0ec-35fc-49a5-aa8a-b0b57403c2d0}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Ba93bd0ec-35fc-49a5-aa8a-b0b57403c2d0%7D"}, "html": {"href": "https://bitbucket.org/%7Ba93bd0ec-35fc-49a5-aa8a-b0b57403c2d0%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/dd56d3105d7602d83d5c35a320f6b36cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsD-6.png"}}, "nickname": "dan77062", "type": "user", "account_id": "557058:e0e36946-cb60-4776-8f47-2e9a0285ad35"}, "updated_on": "2016-12-22T01:41:00.737090+00:00", "type": "issue_comment", "id": 33089714}, {"links": {"self": {"href": "data/repositories/osrf/srcsim/issues/29/comments/33113592.json"}, "html": {"href": "#!/osrf/srcsim/issues/29#comment-33113592"}}, "issue": {"links": {"self": {"href": "data/repositories/osrf/srcsim/issues/29.json"}}, "type": "issue", "id": 29, "repository": {"links": {"self": {"href": "data/repositories/osrf/srcsim.json"}, "html": {"href": "#!/osrf/srcsim"}, "avatar": {"href": "data/bytebucket.org/ravatar/{c41021d9-0217-4628-999d-7f8d82f98dcb}ts=c_plus_plus"}}, "type": "repository", "name": "srcsim", "full_name": "osrf/srcsim", "uuid": "{c41021d9-0217-4628-999d-7f8d82f98dcb}"}, "title": "gazebo head frame or ROS head frame?"}, "content": {"raw": "The wiki has been updated with some clarifications about the head frame:\n\n#!/osrf/srcsim/wiki/qual_task1", "markup": "markdown", "html": "<p>The wiki has been updated with some clarifications about the head frame:</p>\n<p><a href=\"#!/osrf/srcsim/wiki/qual_task1\" rel=\"nofollow\" class=\"ap-connect-link\">#!/osrf/srcsim/wiki/qual_task1</a></p>", "type": "rendered"}, "created_on": "2016-12-22T20:03:20.493376+00:00", "user": {"display_name": "Louise Poubel", "uuid": "{5cfa2075-477b-4ded-bdb9-8d2479544ec4}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B5cfa2075-477b-4ded-bdb9-8d2479544ec4%7D"}, "html": {"href": "https://bitbucket.org/%7B5cfa2075-477b-4ded-bdb9-8d2479544ec4%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:6ff86fcb-b7ab-44a5-b8a6-f6d9cae8b6e8/7d903d90-c5ea-4182-b7ef-0d467e9e1c74/128"}}, "nickname": "chapulina", "type": "user", "account_id": "557058:6ff86fcb-b7ab-44a5-b8a6-f6d9cae8b6e8"}, "updated_on": null, "type": "issue_comment", "id": 33113592}], "page": 1, "size": 10}